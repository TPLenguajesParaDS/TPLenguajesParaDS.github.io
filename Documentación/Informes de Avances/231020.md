# 75.99 Trabajo Profesional

## Avance del proyecto al 20/10/2023

## Índice

- [Informe de Avance de Proyecto](#informe-de-avance-de-proyecto)
  - [Resumen](#resumen)
  - [Hitos y Tareas Completadas](#hitos-y-tareas-completadas)
    - [Hitos Completados](#hitos-completados)
    - [Tareas Completadas](#tareas-completadas)
  - [Problemas, desafíos y/o cambios](#problemas-desafíos-yo-cambios)
  - [Progreso del Cronograma](#progreso-del-cronograma)
  - [Próximos Pasos](#próximos-pasos)
  - [Anexos](#anexos)

## Informe de Avance de Proyecto

### Resumen

A la fecha se han definido los tipos de datasets con los que trabajaremos. Estos se componen de una única columna la cual tendrá un tipo, numérico o de texto, y característica específica, siendo la lista final:

- Enteros (int)
- Números en punto flotante (float)
- Cadenas de caracteres de longitud variable
- Cadenas de caracteres de longitud fija
- Textos.

Para crear estos conjuntos de datos, se ha implementado un generador automático que puede configurarse según el tipo y el tamaño deseado. Para el conjunto de datos de texto, se ha seleccionado la base de datos de Wikipedia y se han creado subconjuntos de distintos tamaños.
Para la generación de los benchmarks se definieron los planes de trabajos con las operaciones que cada lenguaje debe desempeñar a fin de poder realizar las comparaciones. Los grupos de operaciones definidos son:

- de entrada salida: leer y escribir archivos
- aritméticos
- modificaciones
- filtrados
- ordenamientos
- búsquedas

Se armaron los entornos de trabajo containerizados para las pruebas de concepto con Pandas y PySpark. Se comenzó el desarrollo de los scripts correspondientes para cada framework.
Para la completitud de las tareas se debieron tomar algunas decisiones de diseño debido a que no todos los frameworks poseen las mismas funcionalidades nativas. Para solventar esto, se decidió que el dominio del proyecto será orientado para un data science de nivel entry level, en donde las implementaciones de las funciones de los planes de trabajo seguirán la siguiente heurística:

- si el framework / lenguaje provee la funcionalidad, esa será utilizada
- sino se implementara una composición de funciones nativas para la resolución del mismo. Por ejemplo, si la operación que se quiere desempeñar es la búsqueda del índice del máximo número, se utilizará la función para encontrar el máximo y luego la función para buscar el índice en base a un número dado, en este caso el máximo.
- sino se diseñará un algoritmo propio.

Para la recolección de métricas se definió utilizar prometheus y cAdvisor y se realizó una prueba de concepto de las mismas con entornos containerizados.

### Hitos y Tareas Completadas

#### Hitos Completados

- Generador automático de datasets genéricos con esquemas definidos por json
- Definiciones de datasets y planes de proyectos: dataset de ints, floats, cadenas de caracteres de largo variable, de largo fijo y textos extraídos de Wikipedia.

#### Tareas Completadas

- Armado de entornos dockerizados para los frameworks de Pandas y Pyspark
- Pruebas de concepto de cada framework dockerizado en local
- Armado de entorno para la recolección de métricas: cAdvisor + Prometheus

### Problemas, desafíos y/o cambios

- En el generador de datasets resultó muy lento generar textos complejos usando cadenas de Markov [1], por lo que decidimos usar como dataset un dump del contenido de la wikipedia en inglés [2].
- La infraestructura del cluster TUPAC no permite la instalación de imágenes de docker, por lo que su uso para este proyecto se ve comprometido. Como potencial variante vamos a analizar utilizar el cluster MENDIETA[3].

### Progreso del Cronograma

El proyecto se encuentra a tiempo con respecto al cronograma previsto. Se adiciona el armado del entorno para la generación y recepción de las métricas necesarias para armar los benchmarks.

| Épica             | Tarea                                                       | Status          |
| :---------------- | :---------------------------------------------------------- | :-------------- |
| Investigación     | Armado anteproyecto (documentación)                         | Terminado       |
|                   | Definición de herramientas para la generación de benchmarks | Terminado       |
|                   | Definición y generación de datasets                         | Terminado       |
|                   | Definición de planes de tareas                              | Terminado       |
| Análisis de datos | Framework: Pyspark; dataset: numérico                       | Terminado       |
|                   | Framework: Pyspark; dataset: texto                          | En progreso 80% |
|                   | Framework: Pandas; dataset: numérico                        | Terminado       |
|                   | Framework: Pandas; dataset: texto                           | En progreso 90% |
| No planificados   | Armado de entorno para toma de métricas                     | En progreso 70% |

### Próximos Pasos

- Para el próximo sprint vamos a:
  - Concluir las tareas en progreso empezadas en el sprint anterior (scripts de texto en Pandas y Pyspark)
  - Dockerizar los ambientes para Julia y R
  - Escribir los scripts de texto y números para Julia y R
- Realizaremos una prueba de concepto del generador de reportes/resultados, investigando como efectivamente extraer data de prometheus y unirlo a la salida de los scripts.

### Anexos

- [1] https://github.com/jsvine/markovify
- [2] https://ccad.unc.edu.ar/equipamiento/cluster-mendieta/
- [3] https://huggingface.co/datasets/graelo/wikipedia/tree/refs%2Fconvert%2Fparquet/20230601.en/partial-train
